---
title: "Results and Analysis"
---

# 4. Results and Analysis

## 4.1 Model Performance Evaluation

### Confusion Matrices and Accuracy

```{r load-models, include=FALSE}
rf_model <- readRDS("models/rf_model.rds")
nnet_model <- readRDS("models/nnet_model.rds")
balanced_train_data <- readRDS("models/balanced_train_data.rds")
balanced_train_nn <- readRDS("models/balanced_train_nn.rds")
test_data <- readRDS("models/test_data.rds")
test_nn <- readRDS("models/test_nn.rds")
predictor_cols <- readRDS("models/predictor_cols.rds")
top_features <- readRDS("models/top_features.rds")
lime_explanation <- readRDS("models/lime_explanation.rds")
lime_explanation_nn <- readRDS("models/lime_explanation_nn.rds")
rf_importance_df <- readRDS("models/rf_importance_df.rds")
nn_importance_df <- readRDS("models/nn_importance_df.rds")
shap_values <- readRDS("models/shap_values.rds")
shapley_rf <- readRDS("models/shapley_rf.rds")
timing_comparison <- readRDS("models/timing_comparison.rds")

library(caret)
library(pROC)
library(randomForest)

# Predictions
rf_predictions <- predict(rf_model, test_data)
rf_probs <- predict(rf_model, test_data, type = "prob")
rf_cm <- confusionMatrix(rf_predictions, test_data$income)
rf_roc <- roc(test_data$income, rf_probs[, "high"])
rf_auc <- auc(rf_roc)

nnet_probabilities <- predict(nnet_model, test_nn[, top_features], type = "raw")
nnet_predictions <- factor(ifelse(nnet_probabilities > 0.5, "high", "low"), levels = c("low", "high"))
nnet_cm <- confusionMatrix(nnet_predictions, test_data$income)
nnet_roc <- roc(test_data$income, nnet_probabilities)
nnet_auc <- auc(nnet_roc)
```

```{r}
print(rf_cm)
print(nnet_cm)
```

### ROC Curves and AUC Comparison

```{r}
plot(rf_roc, main = "ROC Curves", col = "blue", lwd = 2)
lines(nnet_roc, col = "red", lwd = 2)
legend("bottomright", legend = c(paste("RF AUC =", round(rf_auc, 3)),
                                  paste("NN AUC =", round(nnet_auc, 3))),
       col = c("blue", "red"), lwd = 2)
```

### Confidence Distribution (Optional)

You can optionally add:

```{r}
# Histograms of predicted probabilities
hist(rf_probs[,"high"], main = "RF: Predicted Probabilities for >50K", xlab = "Probability", col = "skyblue")
hist(nnet_probabilities, main = "NN: Predicted Probabilities for >50K", xlab = "Probability", col = "salmon")
```

------------------------------------------------------------------------

## 4.2 Explanation Method Comparison

### Feature Importance Visualization

```{r}
library(ggplot2)

# Random Forest importance plots
p1 <- ggplot(head(rf_importance_df, 10), aes(x = reorder(Feature, MeanDecreaseAccuracy), y = MeanDecreaseAccuracy)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "RF: Top 10 Features by Accuracy Importance") +
  theme_minimal()

p2 <- ggplot(head(rf_importance_df, 10), aes(x = reorder(Feature, MeanDecreaseGini), y = MeanDecreaseGini)) +
  geom_col(fill = "darkgreen") +
  coord_flip() +
  labs(title = "RF: Top 10 Features by Gini Importance") +
  theme_minimal()

print(p1)
print(p2)
```

```{r}
library(ggplot2)
# NN importance plot
nn_importance_df <- nn_importance_df[order(nn_importance_df$Importance, decreasing = TRUE), ]
ggplot(head(nn_importance_df, 10), aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_col(fill = "darkred") +
  coord_flip() +
  labs(title = "NN: Top 10 Features by Absolute Weight", y = "Sum of Absolute Weights") +
  theme_minimal()
```

### Feature Ranking Consistency

```{r}
rf_top10 <- head(rf_importance_df$Feature, 10)
nn_top10 <- head(nn_importance_df$Feature, 10)
intersection <- intersect(rf_top10, nn_top10)
cat("Common top features:", paste(intersection, collapse = ", "), "\n")
```

------------------------------------------------------------------------

## 4.3 Local Explanations: LIME

### LIME Visualizations for Random Forest and NN

```{r lime-plot-improved, fig.width=10, fig.height=8, dpi=300, out.width="100%", fig.align="center"}
library(lime)
cases_rf <- unique(lime_explanation$case)[1:3]
cases_nn <- unique(lime_explanation_nn$case)[1:3]

p_rf <- plot_features(
  lime_explanation[lime_explanation$case %in% cases_rf, ],
  ncol = 1
) + theme(
  text = element_text(size = 14),
  axis.text.y = element_text(size = 12)
)

p_nn <- plot_features(
  lime_explanation_nn[lime_explanation_nn$case %in% cases_nn, ],
  ncol = 1
) + theme(
  text = element_text(size = 14),
  axis.text.y = element_text(size = 12)
)

p_rf
p_nn

```

------------------------------------------------------------------------

------------------------------------------------------------------------

## 4.5 SHAP: Summary and Interactions

### SHAP Summary Values (1 Test Point)

```{r}
plot(shapley_rf)
```

### SHAP Value Ranking

```{r}
library(tidyverse)

shap_top <- shap_values %>%
  dplyr::mutate(phi_abs = abs(phi)) %>%
  dplyr::arrange(desc(phi_abs)) %>%
  head(15)

ggplot(shap_top, aes(x = reorder(feature.value, phi), y = phi)) +
  geom_col(fill = "gray40") +
  coord_flip() +
  labs(title = "Top SHAP Values", x = "Feature", y = "SHAP Value (phi)") +
  theme_minimal()
```

------------------------------------------------------------------------

## 4.6 Computational Efficiency

```{r}
print(timing_comparison)

```

------------------------------------------------------------------------

## Summary

This section presented: - Performance of both models (RF and NN) - Explanation results from LIME and SHAP - Visualization of top features - Consistency and stability analysis - Timing comparison

The next step is to interpret these findings in the context of model transparency and explainability trade-offs.
